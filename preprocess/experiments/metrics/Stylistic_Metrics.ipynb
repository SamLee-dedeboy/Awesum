{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: py-readability-metrics in c:\\users\\aryam\\appdata\\roaming\\python\\python311\\site-packages (1.4.5)\n",
      "Requirement already satisfied: lexical-diversity in c:\\users\\aryam\\appdata\\roaming\\python\\python311\\site-packages (0.1.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from py-readability-metrics) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->py-readability-metrics) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->py-readability-metrics) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->py-readability-metrics) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->py-readability-metrics) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk->py-readability-metrics) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install py-readability-metrics lexical-diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexical_diversity import lex_div as ld\n",
    "from readability import Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use flemmatize if lemmatization and tokenization required otherwise use tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example has 30 sentences, so SMOG works smaller texts(>100 words) can be used for the rest of the metrics.\n",
    "text = \"\"\"The mysterious fog enveloped the old, abandoned mansion. Sparkling stars decorated the night sky in a cosmic dance. Why does the moon seem to follow us wherever we go? Lost in a labyrinth of thoughts, she found solace in poetry. A mischievous squirrel stole my sandwich during the picnic! The aroma of freshly baked cookies filled the cozy kitchen. In a parallel universe, time flows backward, defying logic. Excitement bubbled within her as the roller coaster climbed higher. Have you ever wondered if clouds have secret conversations? The ancient book whispered tales of forgotten civilizations. Laughter echoed through the valleys, creating a symphony of joy. A rainbow painted the horizon after the storm passed. Beware of the talking cat with a penchant for riddles. Enigmatic shadows danced on the walls of the mysterious cave. Moonlight transformed the ordinary forest into a realm of enchantment. Is there a hidden doorway to the land of dreams? Balloons soared into the sky, carrying wishes to unknown destinations. Echoes of a bygone era lingered in the dilapidated castle. The aroma of coffee awakened memories of distant lands. Puzzled by the cryptic message, she embarked on a quest for answers. Sparkling eyes reflected the innocence of a child's laughter. Waves whispered secrets to the curious seashells on the shore. Surrounded by mirrors, the room seemed to stretch into eternity. Chasing fireflies in the summer night brought nostalgic delight. A gentle breeze carried the melody of a distant song. Sudden thunder startled the sleepy town awake. In the heart of the forest, fairies danced under the moonlight. A forgotten key unlocked a chest of ancient artifacts. Reflections in the pond revealed hidden faces of contemplation. The jigsaw puzzle of life slowly revealed its intricate design.\"\"\"\n",
    "tok = ld.tokenize(text)\n",
    "flt = ld.flemmatize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MTLD Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.41249304396217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.mtld(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Readability(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flesch-Kincaid Grade Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.152502283105026\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "fk = r.flesch_kincaid()\n",
    "print(fk.score)\n",
    "print(fk.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flesch Reading Ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.25155707762559\n",
      "fairly_difficult\n",
      "['10', '11', '12']\n"
     ]
    }
   ],
   "source": [
    "f = r.flesch()\n",
    "print(f.score)\n",
    "print(f.ease)\n",
    "print(f.grade_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dale Chall Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.283074703196348\n",
      "['11', '12']\n"
     ]
    }
   ],
   "source": [
    "dc = r.dale_chall()\n",
    "print(dc.score)\n",
    "print(dc.grade_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated Readability Index (ARI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.4221803652968035\n",
      "['8']\n",
      "[13, 14]\n"
     ]
    }
   ],
   "source": [
    "ari = r.ari()\n",
    "print(ari.score)\n",
    "print(ari.grade_levels)\n",
    "print(ari.ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coleman Liau Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.102602739726027\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "cl = r.coleman_liau()\n",
    "print(cl.score)\n",
    "print(cl.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gunning Fog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.783744292237444\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "gf = r.gunning_fog()\n",
    "print(gf.score)\n",
    "print(gf.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.716194520547944\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "s = r.spache()\n",
    "print(s.score)\n",
    "print(s.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linsear Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.433333333333334\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "lw = r.linsear_write()\n",
    "print(lw.score)\n",
    "print(lw.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOG (works for a minimum of 30 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.279547748218288\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "s = r.smog(all_sentences=True)\n",
    "print(s.score)\n",
    "print(s.grade_level)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
