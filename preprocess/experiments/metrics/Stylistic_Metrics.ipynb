{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: py-readability-metrics in c:\\users\\aryam\\appdata\\roaming\\python\\python311\\site-packages (1.4.5)\n",
      "Requirement already satisfied: lexical-diversity in c:\\users\\aryam\\appdata\\roaming\\python\\python311\\site-packages (0.1.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from py-readability-metrics) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->py-readability-metrics) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->py-readability-metrics) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->py-readability-metrics) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->py-readability-metrics) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk->py-readability-metrics) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install py-readability-metrics lexical-diversity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aryam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aryam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexical_diversity import lex_div as ld\n",
    "from readability import Readability\n",
    "import textstat\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use flemmatize if lemmatization and tokenization required otherwise use tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example has 30 sentences, so SMOG works smaller texts(>100 words) can be used for the rest of the metrics.\n",
    "text = \"\"\"The mysterious fog enveloped the old, abandoned mansion. Sparkling stars decorated the night sky in a cosmic dance. Why does the moon seem to follow us wherever we go? Lost in a labyrinth of thoughts, she found solace in poetry. A mischievous squirrel stole my sandwich during the picnic! The aroma of freshly baked cookies filled the cozy kitchen. In a parallel universe, time flows backward, defying logic. Excitement bubbled within her as the roller coaster climbed higher. Have you ever wondered if clouds have secret conversations? The ancient book whispered tales of forgotten civilizations. Laughter echoed through the valleys, creating a symphony of joy. A rainbow painted the horizon after the storm passed. Beware of the talking cat with a penchant for riddles. Enigmatic shadows danced on the walls of the mysterious cave. Moonlight transformed the ordinary forest into a realm of enchantment. Is there a hidden doorway to the land of dreams? Balloons soared into the sky, carrying wishes to unknown destinations. Echoes of a bygone era lingered in the dilapidated castle. The aroma of coffee awakened memories of distant lands. Puzzled by the cryptic message, she embarked on a quest for answers. Sparkling eyes reflected the innocence of a child's laughter. Waves whispered secrets to the curious seashells on the shore. Surrounded by mirrors, the room seemed to stretch into eternity. Chasing fireflies in the summer night brought nostalgic delight. A gentle breeze carried the melody of a distant song. Sudden thunder startled the sleepy town awake. In the heart of the forest, fairies danced under the moonlight. A forgotten key unlocked a chest of ancient artifacts. Reflections in the pond revealed hidden faces of contemplation. The jigsaw puzzle of life slowly revealed its intricate design.\"\"\"\n",
    "tok = ld.tokenize(text)\n",
    "flt = ld.flemmatize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TTR Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6401384083044983"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.ttr(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root TTR\n",
    "\n",
    "Root TTR is calculated as the number of types divided by the square root of the number of tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.882352941176471"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.root_ttr(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log TTR\n",
    "\n",
    "Log TTR is calculated by dividing the logarithm of the number of word types by the logarithm of the number of word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9212782786072363"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.log_ttr(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MASS Index \n",
    "\n",
    "Maas = (log(nTokens) - log(ntypes))/log(ntokens)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031989024503587024"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.maas_ttr(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean-Segmental Type-Token Ratio (MSTTR) \n",
    "\n",
    "It is the average TTR for successive segments of text containing a standard number of word tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869090909090909"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.msttr(flt,window_length=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving-Average Type-Token Ratio\n",
    "\n",
    "MSTTR computes TTR values for equal-sized segments out of the original text and averages the values for each non-overlapping segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8662641509433964"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.mattr(flt,window_length=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypergeometric distribution D (HDD)\n",
    "\n",
    "For each word type in a text, HD-D uses the hypergeometric distribution to calculate the probability of encountering one of its tokens in a random sample of 42 tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8087763082825484"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.hdd(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical Diversity Scores\n",
    "\n",
    "MTLD Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.41249304396217"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.mtld(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of lexical textual diversity (moving average, bi-directional)\n",
    "\n",
    "Revised MTLD procedure that takes a moving-average approach to compute factors. Bidirectional means that the same procedure is repeated in backward, from the last token in the text. The final value is calculated as the average factor lengths out of all the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.25120430107526"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.mtld_ma_bid(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving-average wrapped MTLD\n",
    "\n",
    "Like MTLD-MA-Bi, it takes a moving-average approach to create factors. However, instead of working through the text in both directions, MTLD-MA-Wrap avoids partial factors by looping back to the text's beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.25120430107526"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.mtld_ma_bid(flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of lexical textual diversity (moving average, wrap)\n",
    "\n",
    "Calculates MTLD using a moving window approach. Instead of calculating partial factors, it wraps to the beginning of the text to complete the last factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.68333333333333"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.mtld_ma_wrap(flt)\n",
    "33.68333333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readability Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Readability(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flesch-Kincaid Grade Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.152502283105026\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "fk = r.flesch_kincaid()\n",
    "print(fk.score)\n",
    "print(fk.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flesch Reading Ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.25155707762559\n",
      "fairly_difficult\n",
      "['10', '11', '12']\n"
     ]
    }
   ],
   "source": [
    "f = r.flesch()\n",
    "print(f.score)\n",
    "print(f.ease)\n",
    "print(f.grade_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dale Chall Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.283074703196348\n",
      "['11', '12']\n"
     ]
    }
   ],
   "source": [
    "dc = r.dale_chall()\n",
    "print(dc.score)\n",
    "print(dc.grade_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated Readability Index (ARI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.4221803652968035\n",
      "['8']\n",
      "[13, 14]\n"
     ]
    }
   ],
   "source": [
    "ari = r.ari()\n",
    "print(ari.score)\n",
    "print(ari.grade_levels)\n",
    "print(ari.ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coleman Liau Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.102602739726027\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "cl = r.coleman_liau()\n",
    "print(cl.score)\n",
    "print(cl.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gunning Fog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.783744292237444\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "gf = r.gunning_fog()\n",
    "print(gf.score)\n",
    "print(gf.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.716194520547944\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "s = r.spache()\n",
    "print(s.score)\n",
    "print(s.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linsear Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.433333333333334\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "lw = r.linsear_write()\n",
    "print(lw.score)\n",
    "print(lw.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOG (works for a minimum of 30 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.279547748218288\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "s = r.smog(all_sentences=True)\n",
    "print(s.score)\n",
    "print(s.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIX Readability Formula \n",
    "\n",
    "LIX = total words/total sentences + (total long words(>6) x 100)/total words\n",
    "\n",
    "20-25 : Very Easy\n",
    "\n",
    "30-35 : Easy\n",
    "\n",
    "40-45 : Medium\n",
    "\n",
    "50-55 : Difficult\n",
    "\n",
    "60 above : Very Difficult\n",
    "\n",
    "Source - https://originality.ai/blog/lix-readability-formula#:~:text=To%20compute%20Lix%20scores%2C%20these,average%20words%20in%20the%20sentence.\n",
    "\n",
    "https://readable.com/blog/the-lix-and-rix-readability-formulas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.273471741637834\n"
     ]
    }
   ],
   "source": [
    "def calculate_lix(text):\n",
    "    words = text.split()\n",
    "    long_words = [word for word in words if len(word) > 6]\n",
    "    num_words = len(words)\n",
    "    num_sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "    lix = num_words / num_sentences + (float(len(long_words)) * 100) / num_words\n",
    "    return lix\n",
    "\n",
    "text = \"\"\"The mysterious fog enveloped the old, abandoned mansion. Sparkling stars decorated the night sky in a cosmic dance. Why does the moon seem to follow us wherever we go? Lost in a labyrinth of thoughts, she found solace in poetry. A mischievous squirrel stole my sandwich during the picnic! The aroma of freshly baked cookies filled the cozy kitchen. In a parallel universe, time flows backward, defying logic. Excitement bubbled within her as the roller coaster climbed higher. Have you ever wondered if clouds have secret conversations? The ancient book whispered tales of forgotten civilizations. Laughter echoed through the valleys, creating a symphony of joy. A rainbow painted the horizon after the storm passed. Beware of the talking cat with a penchant for riddles. Enigmatic shadows danced on the walls of the mysterious cave. Moonlight transformed the ordinary forest into a realm of enchantment. Is there a hidden doorway to the land of dreams? Balloons soared into the sky, carrying wishes to unknown destinations. Echoes of a bygone era lingered in the dilapidated castle. The aroma of coffee awakened memories of distant lands. Puzzled by the cryptic message, she embarked on a quest for answers. Sparkling eyes reflected the innocence of a child's laughter. Waves whispered secrets to the curious seashells on the shore. Surrounded by mirrors, the room seemed to stretch into eternity. Chasing fireflies in the summer night brought nostalgic delight. A gentle breeze carried the melody of a distant song. Sudden thunder startled the sleepy town awake. In the heart of the forest, fairies danced under the moonlight. A forgotten key unlocked a chest of ancient artifacts. Reflections in the pond revealed hidden faces of contemplation. The jigsaw puzzle of life slowly revealed its intricate design.\"\"\"\n",
    "print(calculate_lix(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "McAlpine EFLAW Readability Score\n",
    "\n",
    "Returns a score for the readability of an english text for a foreign learner or English, focusing on the number of miniwords and length of sentences.\n",
    "\n",
    "It is recommended to aim for a score equal to or lower than 25.\n",
    "\n",
    "Source: https://strainindex.wordpress.com/2009/04/30/mcalpine-eflaw-readability-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textstat.mcalpine_eflaw(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Time for the given text(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.37"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textstat.reading_time(text, ms_per_char=14.69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formality Score\n",
    "\n",
    " F = (noun frequency + adjective freq. + preposition freq. + article freq. – pronoun freq.– verb freq. – adverb freq. – interjection freq. + 100)/2\n",
    "\n",
    " The frequencies are here expressed as percentages of the number of words belonging to\n",
    " a particular category with respect to the total number of words in the excerpt\n",
    "\n",
    " Source : https://www.researchgate.net/profile/Francis-Heylighen/publication/2420048_Formality_of_Language_definition_measurement_and_behavioral_determinants/links/0912f50584d98e852d000000/Formality-of-Language-definition-measurement-and-behavioral-determinants.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NN': 67, 'DT': 49, 'IN': 44, '.': 30, 'JJ': 29, 'NNS': 28, 'VBD': 24, ',': 9, 'VBN': 8, 'VBG': 7, 'PRP': 6, 'TO': 5, 'VBZ': 4, 'VBP': 4, 'RB': 4, 'NNP': 3, 'VB': 2, 'PRP$': 2, 'WRB': 1, 'JJR': 1, 'POS': 1, 'JJS': 1})\n",
      "74.46808510638299\n"
     ]
    }
   ],
   "source": [
    "def calculate_formality_score(text):\n",
    "    # Tokenize an tag\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    pos_counts = Counter(tag for word, tag in pos_tags)\n",
    "    print(pos_counts)\n",
    "    \n",
    "    # Calculate the frequencies as percentages\n",
    "    total_words = len(words)\n",
    "    noun_freq = (pos_counts['NN'] + pos_counts['NNS'] + pos_counts['NNP'] + pos_counts['NNPS']) / total_words * 100\n",
    "    adjective_freq = (pos_counts['JJ'] + pos_counts['JJR'] + pos_counts['JJS']) / total_words * 100\n",
    "    preposition_freq = pos_counts['IN'] / total_words * 100\n",
    "    article_freq = (pos_counts['DT'] + pos_counts['WDT']) / total_words * 100\n",
    "    pronoun_freq = (pos_counts['PRP'] + pos_counts['PRP$'] + pos_counts['WP'] + pos_counts['WP$']) / total_words * 100\n",
    "    verb_freq = (pos_counts['VB'] + pos_counts['VBD'] + pos_counts['VBG'] + pos_counts['VBN'] + pos_counts['VBP'] + pos_counts['VBZ']) / total_words * 100\n",
    "    adverb_freq = (pos_counts['RB'] + pos_counts['RBR'] + pos_counts['RBS']) / total_words * 100\n",
    "    interjection_freq = pos_counts['UH'] / total_words * 100\n",
    "    \n",
    "    # Formality score formula\n",
    "    F = (noun_freq + adjective_freq + preposition_freq + article_freq - pronoun_freq - verb_freq - adverb_freq - interjection_freq + 100) / 2\n",
    "    \n",
    "    return F\n",
    "\n",
    "text = \"\"\"The mysterious fog enveloped the old, abandoned mansion. Sparkling stars decorated the night sky in a cosmic dance. Why does the moon seem to follow us wherever we go? Lost in a labyrinth of thoughts, she found solace in poetry. A mischievous squirrel stole my sandwich during the picnic! The aroma of freshly baked cookies filled the cozy kitchen. In a parallel universe, time flows backward, defying logic. Excitement bubbled within her as the roller coaster climbed higher. Have you ever wondered if clouds have secret conversations? The ancient book whispered tales of forgotten civilizations. Laughter echoed through the valleys, creating a symphony of joy. A rainbow painted the horizon after the storm passed. Beware of the talking cat with a penchant for riddles. Enigmatic shadows danced on the walls of the mysterious cave. Moonlight transformed the ordinary forest into a realm of enchantment. Is there a hidden doorway to the land of dreams? Balloons soared into the sky, carrying wishes to unknown destinations. Echoes of a bygone era lingered in the dilapidated castle. The aroma of coffee awakened memories of distant lands. Puzzled by the cryptic message, she embarked on a quest for answers. Sparkling eyes reflected the innocence of a child's laughter. Waves whispered secrets to the curious seashells on the shore. Surrounded by mirrors, the room seemed to stretch into eternity. Chasing fireflies in the summer night brought nostalgic delight. A gentle breeze carried the melody of a distant song. Sudden thunder startled the sleepy town awake. In the heart of the forest, fairies danced under the moonlight. A forgotten key unlocked a chest of ancient artifacts. Reflections in the pond revealed hidden faces of contemplation. The jigsaw puzzle of life slowly revealed its intricate design.\"\"\"\n",
    "formality_score = calculate_formality_score(text)\n",
    "print(formality_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
