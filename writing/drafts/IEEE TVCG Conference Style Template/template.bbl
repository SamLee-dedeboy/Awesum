\begin{thebibliography}{10}

\bibitem{bhandari2020re}
M.~Bhandari, P.~Gour, A.~Ashfaq, P.~Liu, and G.~Neubig.
\newblock Re-evaluating evaluation in text summarization.
\newblock {\em arXiv preprint arXiv:2010.07100}, 2020.

\bibitem{deutsch2022re}
D.~Deutsch, R.~Dror, and D.~Roth.
\newblock Re-examining system-level correlations of automatic summarization
  evaluation metrics.
\newblock {\em arXiv preprint arXiv:2204.10216}, 2022.

\bibitem{durmus2020feqa}
E.~Durmus, H.~He, and M.~Diab.
\newblock Feqa: A question answering evaluation framework for faithfulness
  assessment in abstractive summarization.
\newblock {\em arXiv preprint arXiv:2005.03754}, 2020.

\bibitem{durmus2022spurious}
E.~Durmus, F.~Ladhak, and T.~Hashimoto.
\newblock Spurious correlations in reference-free evaluation of text
  generation.
\newblock {\em arXiv preprint arXiv:2204.09890}, 2022.

\bibitem{honovich2021q2}
O.~Honovich, L.~Choshen, R.~Aharoni, E.~Neeman, I.~Szpektor, and O.~Abend.
\newblock {$Q^2$}: Evaluating factual consistency in knowledge-grounded
  dialogues via question generation and question answering.
\newblock {\em arXiv preprint arXiv:2104.08202}, 2021.

\bibitem{lin2004rouge}
C.-Y. Lin.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In {\em Text summarization branches out}, pp. 74--81, 2004.

\bibitem{lucchese2023can}
C.~Lucchese, G.~Minello, F.~M. Nardini, S.~Orlando, R.~Perego, and A.~Veneri.
\newblock Can embeddings analysis explain large language model ranking?
\newblock In {\em Proceedings of the 32nd ACM International Conference on
  Information and Knowledge Management}, pp. 4150--4154, 2023.

\bibitem{mishra2023promptaid}
A.~Mishra, U.~Soni, A.~Arunkumar, J.~Huang, B.~C. Kwon, and C.~Bryan.
\newblock Promptaid: Prompt exploration, perturbation, testing and iteration
  using visual analytics for large language models.
\newblock {\em arXiv preprint arXiv:2304.01964}, 2023.

\bibitem{novikova2017we}
J.~Novikova, O.~Du{\v{s}}ek, A.~C. Curry, and V.~Rieser.
\newblock Why we need new evaluation metrics for nlg.
\newblock {\em arXiv preprint arXiv:1707.06875}, 2017.

\bibitem{peyrard2017learning}
M.~Peyrard, T.~Botschen, and I.~Gurevych.
\newblock Learning to score system summaries for better content selection
  evaluation.
\newblock In {\em Proceedings of the Workshop on New Frontiers in
  Summarization}, pp. 74--84, 2017.

\bibitem{zhou2022large}
Y.~Zhou, A.~I. Muresanu, Z.~Han, K.~Paster, S.~Pitis, H.~Chan, and J.~Ba.
\newblock Large language models are human-level prompt engineers.
\newblock {\em arXiv preprint arXiv:2211.01910}, 2022.

\end{thebibliography}
